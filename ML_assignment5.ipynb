{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3WDPbsYk4fp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qz6nxQ8slMGY",
        "outputId": "311d54df-2219-4bfc-e0b1-8a992e19df4e"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/abalone.data - abalone.data.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-dd86950b13c8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/abalone.data - abalone.data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/abalone.data - abalone.data.csv'"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"/content/abalone.data - abalone.data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kNtEq9yoR5bJ"
      },
      "outputs": [],
      "source": [
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zN4U5SVFQhaE"
      },
      "outputs": [],
      "source": [
        "data = pd.get_dummies(data, columns=['Sex'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "w6khscQkRGRQ"
      },
      "outputs": [],
      "source": [
        "continuous_features = ['Length',  'Diameter' , 'Height' , 'Whole_weight',  'Shucked_weight',  'Viscera_weight', 'Shell_weight']\n",
        "scaler = StandardScaler()\n",
        "data[continuous_features] = scaler.fit_transform(data[continuous_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WUWpDMtKUTAj"
      },
      "outputs": [],
      "source": [
        "data = data.astype(float)\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "huuYZvviS-AY"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uywpyjxkTTVd"
      },
      "outputs": [],
      "source": [
        "X = data.drop(columns=['Rings'])\n",
        "y = data['Rings']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "owT1HMeST-Cf"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "08VRIcT3T_q8"
      },
      "outputs": [],
      "source": [
        "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "l9jI3bRbU816"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_dim=10, hidden_dim1=64, hidden_dim2=32, output_dim=1):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
        "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
        "        self.fc3 = nn.Linear(hidden_dim2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "abQhinkxX24Y"
      },
      "outputs": [],
      "source": [
        "model= NeuralNetwork(input_dim=10, hidden_dim1=64, hidden_dim2=32, output_dim=1)\n",
        "print(model)\n",
        "import torch.optim as optim\n",
        "model = NeuralNetwork()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5_qnp4B-VHEh"
      },
      "outputs": [],
      "source": [
        "#Mean Squared Error (MSE) loss function\n",
        "criterion = nn.MSELoss()\n",
        "# Stochastic Gradient Descent (SGD) optimizer with learning rate 0.1\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nBxOe3ncYVEe"
      },
      "outputs": [],
      "source": [
        "num_epochs=100\n",
        "def train_model(model, criterion, optimizer, X_train, y_train, num_epochs=100):\n",
        "    for epoch in range(num_epochs):\n",
        "      loss=[]\n",
        "        # Set the model to training mode\n",
        "model.train()\n",
        "\n",
        " # Forward pass\n",
        "outputs = model(X_train_tensor)\n",
        "loss = criterion(outputs, y_train_tensor)\n",
        "\n",
        "# Backward pass and optimization\n",
        "optimizer.zero_grad()\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "for epoch in range(num_epochs):\n",
        "# Print training loss every 10 epochs\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
        "\n",
        "def evaluate(model, criterion, X_test, y_test):\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Disable gradient calculation\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X_test)\n",
        "        loss = criterion(outputs, y_test)  # Ensure target has same shape as output\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "# Train the model\n",
        "train_model(model, criterion, optimizer, X_train_tensor, y_train_tensor, num_epochs=100)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = evaluate(model, criterion, X_test_tensor, y_test_tensor)\n",
        "print(f'Mean Squared Error (MSE) on Testing Set: {mse}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TlcNah8IeUNp"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, criterion, X_test, y_test):\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "learning_rates = [0.001, 0.01, 0.1]\n",
        "batch_sizes = [32, 64, 128]\n",
        "hidden_nodes = [32, 64, 128]\n",
        "hidden_layers = [1, 2, 3]\n",
        "\n",
        "results = {}\n",
        "\n",
        "# Iterate over different hyperparameter combinations\n",
        "for lr in learning_rates:\n",
        "    for bs in batch_sizes:\n",
        "        for hn in hidden_nodes:\n",
        "            for hl in hidden_layers:\n",
        "                # Define and train the model\n",
        "                model =NeuralNetwork(input_dim=10, hidden_dim1=hn, hidden_dim2=hn, output_dim=1)\n",
        "                optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "                train_model(model, criterion, optimizer, X_train_tensor, y_train_tensor, num_epochs=100)\n",
        "\n",
        "                # Evaluate the model\n",
        "                mse = evaluate(model, criterion, X_test_tensor, y_test_tensor)\n",
        "\n",
        "                # Store the results\n",
        "                results[(lr, bs, hn, hl)] = mse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NRq7E2T9kzJk"
      },
      "outputs": [],
      "source": [
        "results_sgd = {}\n",
        "results_adagrad = {}\n",
        "\n",
        "# Iterate over different hyperparameter combinations\n",
        "for lr in learning_rates:\n",
        "    for bs in batch_sizes:\n",
        "        for hn in hidden_nodes:\n",
        "            for hl in hidden_layers:\n",
        "                # Define and train the model with SGD optimizer\n",
        "                model_sgd =NeuralNetwork(input_dim=10, hidden_dim1=hn, hidden_dim2=hn, output_dim=1)\n",
        "                optimizer_sgd = optim.SGD(model_sgd.parameters(), lr=lr)\n",
        "                train_model(model_sgd, criterion, optimizer_sgd, X_train_tensor, y_train_tensor, num_epochs=100)\n",
        "                mse_sgd = evaluate(model_sgd, criterion, X_test_tensor, y_test_tensor)\n",
        "                results_sgd[(lr, bs, hn, hl)] = mse_sgd\n",
        "\n",
        "                # Define and train the model with Adagrad optimizer\n",
        "                model_adagrad =NeuralNetwork(input_dim=10, hidden_dim1=hn, hidden_dim2=hn, output_dim=1)\n",
        "                optimizer_adagrad = optim.Adagrad(model_adagrad.parameters(), lr=lr)\n",
        "                train_model(model_adagrad, criterion, optimizer_adagrad, X_train_tensor, y_train_tensor, num_epochs=100)\n",
        "                mse_adagrad = evaluate(model_adagrad, criterion, X_test_tensor, y_test_tensor)\n",
        "                results_adagrad[(lr, bs, hn, hl)] = mse_adagrad\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TsMm1hMomj8V"
      },
      "outputs": [],
      "source": [
        "class NeuralNetworkWithSigmoid(nn.Module):\n",
        "    def __init__(self, input_dim=10, hidden_layers=10, hidden_dim=64, output_dim=1):\n",
        "        super(NeuralNetworkWithSigmoid, self).__init__()\n",
        "        self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
        "        self.hidden_layers = nn.ModuleList([\n",
        "            nn.Linear(hidden_dim, hidden_dim) for _ in range(hidden_layers)\n",
        "        ])\n",
        "        self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.sigmoid(self.input_layer(x))\n",
        "        for hidden_layer in self.hidden_layers:\n",
        "            x = self.sigmoid(hidden_layer(x))\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "# Model with 10 hidden layers\n",
        "model_with_sigmoid_10_layers =NeuralNetworkWithSigmoid(hidden_layers=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dPjL7WQ7oPap"
      },
      "outputs": [],
      "source": [
        "# Sigmoid function in Python\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + torch.exp(-x))\n",
        "x_values = np.linspace(-5, 5, 50)\n",
        "x_values_tensor = torch.tensor(x_values, dtype=torch.float32)\n",
        "y_values_tensor = sigmoid(x_values_tensor)\n",
        "\n",
        "plt.plot(x_values, y_values_tensor.numpy())\n",
        "plt.title('Sigmoid Function')\n",
        "plt.xlabel('Input')\n",
        "plt.ylabel('Output')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}